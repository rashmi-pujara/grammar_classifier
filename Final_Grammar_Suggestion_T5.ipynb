{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6bb6c5fd366646cbb4b501b121788838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b36cf2774ad49d18bb26b9c9cf560ed",
              "IPY_MODEL_c7b8358a5d8f48b3b0b154bfc7f494c3",
              "IPY_MODEL_db4d3dc961c246e79530a67e94cff6c4"
            ],
            "layout": "IPY_MODEL_0e982e3981f049bea53b8a56dba7b39d"
          }
        },
        "8b36cf2774ad49d18bb26b9c9cf560ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f0055cb61e444c29f528b2437701b37",
            "placeholder": "​",
            "style": "IPY_MODEL_31d1cbfd855d4946ad0d663872c185a2",
            "value": "Downloading (…)ve/main/spiece.model: 100%"
          }
        },
        "c7b8358a5d8f48b3b0b154bfc7f494c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24167d75692747f799db4ccd7cde4f66",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e92d9e8b1184ce7984b9b291b473b0d",
            "value": 791656
          }
        },
        "db4d3dc961c246e79530a67e94cff6c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdb68500824e48f1a3fbc3dbcc1ba19f",
            "placeholder": "​",
            "style": "IPY_MODEL_30314f890702438cacbcaa6207fdbf57",
            "value": " 792k/792k [00:00&lt;00:00, 1.39MB/s]"
          }
        },
        "0e982e3981f049bea53b8a56dba7b39d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f0055cb61e444c29f528b2437701b37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31d1cbfd855d4946ad0d663872c185a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24167d75692747f799db4ccd7cde4f66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e92d9e8b1184ce7984b9b291b473b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fdb68500824e48f1a3fbc3dbcc1ba19f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30314f890702438cacbcaa6207fdbf57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fa1a7132a2340eb8943363a30cb108d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04dfcfc39f19407eba3db187fe3f8093",
              "IPY_MODEL_b86da4073def40408e14c1d0db83fdb6",
              "IPY_MODEL_f51096895cfc4e47a401de34ee6d48e3"
            ],
            "layout": "IPY_MODEL_505f33cac2b04ade96c1114a9544575a"
          }
        },
        "04dfcfc39f19407eba3db187fe3f8093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba03a25440474afb876db71ae3d0dadc",
            "placeholder": "​",
            "style": "IPY_MODEL_07ba1dfe74e245e99f01edc2d9c662d8",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "b86da4073def40408e14c1d0db83fdb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_895fb0eb89b0405b8013913462a3dd80",
            "max": 1208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bef670c05a9c4d7d81ac2fcde8ff4784",
            "value": 1208
          }
        },
        "f51096895cfc4e47a401de34ee6d48e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9be663470174996b768cdfebb1034dc",
            "placeholder": "​",
            "style": "IPY_MODEL_301e05be03a848c9961722f3314e8152",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 24.6kB/s]"
          }
        },
        "505f33cac2b04ade96c1114a9544575a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba03a25440474afb876db71ae3d0dadc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07ba1dfe74e245e99f01edc2d9c662d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "895fb0eb89b0405b8013913462a3dd80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bef670c05a9c4d7d81ac2fcde8ff4784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9be663470174996b768cdfebb1034dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "301e05be03a848c9961722f3314e8152": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83af3c977a894bdca70f2aa16cdf0a05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc34ecf62207458aa5285df564a46f75",
              "IPY_MODEL_9bedbddcc5d744bab0752facd087bcaf",
              "IPY_MODEL_268198beb5054a31abb359e17359e944"
            ],
            "layout": "IPY_MODEL_f22fabef99394df4b0b6f7119297c7d8"
          }
        },
        "dc34ecf62207458aa5285df564a46f75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc9b482fa2b341488beb7c80d8458a94",
            "placeholder": "​",
            "style": "IPY_MODEL_a171f8d7bd4c44fcac021699f34a2fa3",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "9bedbddcc5d744bab0752facd087bcaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2c0465e14514b79b404be82fec8a411",
            "max": 891691430,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20cf91e3d1f443f9948440d02408f7b8",
            "value": 891691430
          }
        },
        "268198beb5054a31abb359e17359e944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_260b98051f364c188e3bdd2fff45127c",
            "placeholder": "​",
            "style": "IPY_MODEL_e5a8d96bc55b4ea684dccb902a3bf885",
            "value": " 892M/892M [00:10&lt;00:00, 90.7MB/s]"
          }
        },
        "f22fabef99394df4b0b6f7119297c7d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc9b482fa2b341488beb7c80d8458a94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a171f8d7bd4c44fcac021699f34a2fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2c0465e14514b79b404be82fec8a411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20cf91e3d1f443f9948440d02408f7b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "260b98051f364c188e3bdd2fff45127c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5a8d96bc55b4ea684dccb902a3bf885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cabb35a540ad4441a0367c91f3a53e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ac625dd05e64d8a86d05de1afb795db",
              "IPY_MODEL_35925938b9cc4f3f80f7eb6b013d856d",
              "IPY_MODEL_d26693dd98c54dbcb60c512d516f05fc"
            ],
            "layout": "IPY_MODEL_9f48f960a5f44e64801fdb85d9b775fa"
          }
        },
        "2ac625dd05e64d8a86d05de1afb795db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fffae96dbe34e15a1f7a3f63fbacdf3",
            "placeholder": "​",
            "style": "IPY_MODEL_30c3d9722341463da3dd8e82a558424d",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "35925938b9cc4f3f80f7eb6b013d856d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3e9cf2d79274e3790fa1895b363a431",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47d7f452ed44493f8c018e19629de2d3",
            "value": 147
          }
        },
        "d26693dd98c54dbcb60c512d516f05fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6845444cf62348619c18df33470349d3",
            "placeholder": "​",
            "style": "IPY_MODEL_418ee678e5014007987cdf2d4c4b142c",
            "value": " 147/147 [00:00&lt;00:00, 4.51kB/s]"
          }
        },
        "9f48f960a5f44e64801fdb85d9b775fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fffae96dbe34e15a1f7a3f63fbacdf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30c3d9722341463da3dd8e82a558424d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3e9cf2d79274e3790fa1895b363a431": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47d7f452ed44493f8c018e19629de2d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6845444cf62348619c18df33470349d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "418ee678e5014007987cdf2d4c4b142c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3f12509e3be4b3c919640a7035a8f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d28e5e42a53445ca82962fe16775dac",
              "IPY_MODEL_b3fd50b0d3404a9296b7e1dac1228613",
              "IPY_MODEL_b65e4d2b814a4a2095fb90d41e4f3a67"
            ],
            "layout": "IPY_MODEL_40dcb6ec3e99458eb2b466d09817405f"
          }
        },
        "0d28e5e42a53445ca82962fe16775dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31d97fddbff94a998598459e2e678583",
            "placeholder": "​",
            "style": "IPY_MODEL_01365f409089447e9af854fed9df2b4d",
            "value": "Downloading builder script: "
          }
        },
        "b3fd50b0d3404a9296b7e1dac1228613": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ccdf354aaa342109c2db97cd963faa5",
            "max": 2160,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddb024309de8413b93ac977a0265e850",
            "value": 2160
          }
        },
        "b65e4d2b814a4a2095fb90d41e4f3a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a20ada0461c4312aab9d8ced526c672",
            "placeholder": "​",
            "style": "IPY_MODEL_f72885ae0fc64f74841e236cdc9f5131",
            "value": " 5.60k/? [00:00&lt;00:00, 264kB/s]"
          }
        },
        "40dcb6ec3e99458eb2b466d09817405f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31d97fddbff94a998598459e2e678583": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01365f409089447e9af854fed9df2b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ccdf354aaa342109c2db97cd963faa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddb024309de8413b93ac977a0265e850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a20ada0461c4312aab9d8ced526c672": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f72885ae0fc64f74841e236cdc9f5131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qk6pbPWODQ_C",
        "outputId": "360507d2-304f-4c74-8632-51a8f528620c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.9.0-py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Collecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m520.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, urllib3, multiprocess, responses, huggingface-hub, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.9.0 huggingface-hub-0.12.0 multiprocess-0.70.14 responses-0.18.0 urllib3-1.26.14 xxhash-3.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets tqdm pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ2psUaEEMfn",
        "outputId": "d62f57e1-df7f-437d-f35e-60d0bd6077c8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZV2x3PVER5T",
        "outputId": "d7d154f8-7027-4df8-b253-fc9678078580"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "Successfully installed tokenizers-0.13.2 transformers-4.26.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njdzS08RETae",
        "outputId": "1eaca893-e177-4e56-fe0f-624dee0e0a09"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.9-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from wandb) (4.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.25.1)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.14.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (7.1.2)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.30-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.14)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=61f037caa629e413ba6d465414b1fac39968da7138c4a9e5eb131fb32083b0c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.30 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.14.0 setproctitle-1.3.2 smmap-5.0.0 wandb-0.13.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "tlsSTZWIEX5Q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import logging\n",
        "import random\n",
        "import re\n",
        "from itertools import chain\n",
        "from string import punctuation"
      ],
      "metadata": {
        "id": "JT4s9L7hEcxf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgMLLowaFCB7",
        "outputId": "a047e94e-5919-47cc-db2d-e2f7e4681688"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "mlXaaSifFD6N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AdamW,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    get_linear_schedule_with_warmup\n",
        ")"
      ],
      "metadata": {
        "id": "yxpgbPfxFHUO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import datasets"
      ],
      "metadata": {
        "id": "r7O91XMrFJg8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "h8ZIGmvtFLzr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', None)"
      ],
      "metadata": {
        "id": "o3RsU9arFckC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv('c4_200m_550k.csv')\n",
        "# df.shape"
      ],
      "metadata": {
        "id": "xTFDJ0zoFgNh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df.head()"
      ],
      "metadata": {
        "id": "V_PmIwtkFmOC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    T5ForConditionalGeneration, T5Tokenizer, \n",
        "    Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
        "  )\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "9BaBHmxaJICT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 't5-base'\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "6bb6c5fd366646cbb4b501b121788838",
            "8b36cf2774ad49d18bb26b9c9cf560ed",
            "c7b8358a5d8f48b3b0b154bfc7f494c3",
            "db4d3dc961c246e79530a67e94cff6c4",
            "0e982e3981f049bea53b8a56dba7b39d",
            "1f0055cb61e444c29f528b2437701b37",
            "31d1cbfd855d4946ad0d663872c185a2",
            "24167d75692747f799db4ccd7cde4f66",
            "6e92d9e8b1184ce7984b9b291b473b0d",
            "fdb68500824e48f1a3fbc3dbcc1ba19f",
            "30314f890702438cacbcaa6207fdbf57",
            "4fa1a7132a2340eb8943363a30cb108d",
            "04dfcfc39f19407eba3db187fe3f8093",
            "b86da4073def40408e14c1d0db83fdb6",
            "f51096895cfc4e47a401de34ee6d48e3",
            "505f33cac2b04ade96c1114a9544575a",
            "ba03a25440474afb876db71ae3d0dadc",
            "07ba1dfe74e245e99f01edc2d9c662d8",
            "895fb0eb89b0405b8013913462a3dd80",
            "bef670c05a9c4d7d81ac2fcde8ff4784",
            "a9be663470174996b768cdfebb1034dc",
            "301e05be03a848c9961722f3314e8152",
            "83af3c977a894bdca70f2aa16cdf0a05",
            "dc34ecf62207458aa5285df564a46f75",
            "9bedbddcc5d744bab0752facd087bcaf",
            "268198beb5054a31abb359e17359e944",
            "f22fabef99394df4b0b6f7119297c7d8",
            "cc9b482fa2b341488beb7c80d8458a94",
            "a171f8d7bd4c44fcac021699f34a2fa3",
            "e2c0465e14514b79b404be82fec8a411",
            "20cf91e3d1f443f9948440d02408f7b8",
            "260b98051f364c188e3bdd2fff45127c",
            "e5a8d96bc55b4ea684dccb902a3bf885",
            "cabb35a540ad4441a0367c91f3a53e86",
            "2ac625dd05e64d8a86d05de1afb795db",
            "35925938b9cc4f3f80f7eb6b013d856d",
            "d26693dd98c54dbcb60c512d516f05fc",
            "9f48f960a5f44e64801fdb85d9b775fa",
            "3fffae96dbe34e15a1f7a3f63fbacdf3",
            "30c3d9722341463da3dd8e82a558424d",
            "d3e9cf2d79274e3790fa1895b363a431",
            "47d7f452ed44493f8c018e19629de2d3",
            "6845444cf62348619c18df33470349d3",
            "418ee678e5014007987cdf2d4c4b142c"
          ]
        },
        "id": "H2bFwtclJLuS",
        "outputId": "36bf450c-7f51-4657-ff28-80f8b1174885"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6bb6c5fd366646cbb4b501b121788838"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4fa1a7132a2340eb8943363a30cb108d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83af3c977a894bdca70f2aa16cdf0a05"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cabb35a540ad4441a0367c91f3a53e86"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_token_len(example):\n",
        "    return len(tokenizer(example).input_ids)"
      ],
      "metadata": {
        "id": "mJQbNy_dJN_k"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# train_df, test_df = train_test_split(df, test_size=0.95, shuffle=True)\n",
        "# train_df.shape, test_df.shape"
      ],
      "metadata": {
        "id": "72gbqpDRJRPa"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test_df['input_token_len'] = test_df['input'].apply(calc_token_len)"
      ],
      "metadata": {
        "id": "-WNIB8FPJUqS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test_df['input_token_len'].describe()"
      ],
      "metadata": {
        "id": "RDxrAkHDJXSA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from datasets import Dataset\n",
        "# train_dataset = Dataset.from_pandas(train_df)\n",
        "# test_dataset = Dataset.from_pandas(test_df)"
      ],
      "metadata": {
        "id": "tC4JA4PLJYuY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class GrammarDataset(Dataset):\n",
        "    def __init__(self, dataset, tokenizer,print_text=False):         \n",
        "        self.dataset = dataset\n",
        "        self.pad_to_max_length = False\n",
        "        self.tokenizer = tokenizer\n",
        "        self.print_text = print_text\n",
        "        self.max_len = 64\n",
        "  \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "\n",
        "    def tokenize_data(self, example):\n",
        "        input_, target_ = example['input'], example['output']\n",
        "\n",
        "        # tokenize inputs\n",
        "        tokenized_inputs = tokenizer(input_, pad_to_max_length=self.pad_to_max_length, \n",
        "                                            max_length=self.max_len,\n",
        "                                            return_attention_mask=True)\n",
        "    \n",
        "        tokenized_targets = tokenizer(target_, pad_to_max_length=self.pad_to_max_length, \n",
        "                                            max_length=self.max_len,\n",
        "                                            return_attention_mask=True)\n",
        "\n",
        "        inputs={\"input_ids\": tokenized_inputs['input_ids'],\n",
        "            \"attention_mask\": tokenized_inputs['attention_mask'],\n",
        "            \"labels\": tokenized_targets['input_ids']\n",
        "        }\n",
        "        \n",
        "        return inputs\n",
        "\n",
        "  \n",
        "    def __getitem__(self, index):\n",
        "        inputs = self.tokenize_data(self.dataset[index])\n",
        "        \n",
        "        if self.print_text:\n",
        "            for k in inputs.keys():\n",
        "                print(k, len(inputs[k]))\n",
        "\n",
        "        return inputs"
      ],
      "metadata": {
        "id": "TDSmNVfqJg28"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset = GrammarDataset(test_dataset, tokenizer, True)\n",
        "# print(dataset[121])"
      ],
      "metadata": {
        "id": "ns5ABeM5J7I8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_iOnCy8J81V",
        "outputId": "34353ab9-162e-45c9-8f61-512edde3851d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from rouge_score) (1.3.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from rouge_score) (3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from rouge_score) (1.21.6)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from rouge_score) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->rouge_score) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk->rouge_score) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk->rouge_score) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->rouge_score) (1.2.0)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=3675bb07494d61433c421fae5b6e408ce18d17bc9253928fd673f13d175768dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/24/55/6f/ebfc4cb176d1c9665da4e306e1705496206d08215c1acd9dde\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "rouge_metric = load_metric(\"rouge\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "f3f12509e3be4b3c919640a7035a8f24",
            "0d28e5e42a53445ca82962fe16775dac",
            "b3fd50b0d3404a9296b7e1dac1228613",
            "b65e4d2b814a4a2095fb90d41e4f3a67",
            "40dcb6ec3e99458eb2b466d09817405f",
            "31d97fddbff94a998598459e2e678583",
            "01365f409089447e9af854fed9df2b4d",
            "1ccdf354aaa342109c2db97cd963faa5",
            "ddb024309de8413b93ac977a0265e850",
            "0a20ada0461c4312aab9d8ced526c672",
            "f72885ae0fc64f74841e236cdc9f5131"
          ]
        },
        "id": "lrD4NsB_J_um",
        "outputId": "06621903-d5b7-4567-93b3-c6a6158c9aba"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-76fa4d2ef6b0>:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  rouge_metric = load_metric(\"rouge\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3f12509e3be4b3c919640a7035a8f24"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding='longest', return_tensors='pt')"
      ],
      "metadata": {
        "id": "nOCjKuwgKCzk"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "args = Seq2SeqTrainingArguments(output_dir=\"/content/drive/MyDrive/c4_200m/weights\",\n",
        "                        evaluation_strategy=\"steps\",\n",
        "                        per_device_train_batch_size=batch_size,\n",
        "                        per_device_eval_batch_size=batch_size,\n",
        "                        learning_rate=2e-5,\n",
        "                        num_train_epochs=5,\n",
        "                        weight_decay=0.01,\n",
        "                        save_total_limit=2,\n",
        "                        predict_with_generate=True,\n",
        "                        fp16 = True,\n",
        "                        gradient_accumulation_steps = 6,\n",
        "                        eval_steps = 20,\n",
        "                        save_steps = 20,\n",
        "                        load_best_model_at_end=True,\n",
        "                        logging_dir=\"/logs\",\n",
        "                        report_to=\"wandb\")"
      ],
      "metadata": {
        "id": "JDrLQdB0KL-6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    \n",
        "    # Rouge expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "    \n",
        "    result = rouge_metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    # Extract a few results\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "    \n",
        "    # Add mean generated length\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IsFjL8WKQGl",
        "outputId": "cc01818a-314c-4175-bb17-88f4dbfa8a74"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset \n",
        "\n",
        "test_data = pd.read_csv(\"Questions_Generations_Annotations.csv\", encoding= 'unicode_escape')\n",
        "\n",
        "test_data.head()\n",
        "\n",
        "test_data = test_data[2:]\n",
        "\n",
        "test_data[test_data[\"Correct Grammar\"] != \"0\"]\n",
        "\n",
        "clean_test_data = test_data.drop(test_data[test_data[\"Correct Grammar\"] != \"0\"].index)\n",
        "\n",
        "clean_test_data = clean_test_data.loc[:, [\"Sample\", \"Suggestions\"]]\n",
        "\n",
        "clean_test_data['input_token_len'] = clean_test_data['Sample'].apply(calc_token_len)\n",
        "\n",
        "\n",
        "clean_test_data = clean_test_data.rename(columns={'Sample': 'input', 'Suggestions': 'output'})\n",
        "\n",
        "\n",
        "eval_data = Dataset.from_pandas(clean_test_data)"
      ],
      "metadata": {
        "id": "3wK0olu6-FC2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer = Seq2SeqTrainer(model=model, \n",
        "#                 args=args, \n",
        "#                 train_dataset= GrammarDataset(train_dataset, tokenizer),\n",
        "#                 eval_dataset=GrammarDataset(eval_data, tokenizer),\n",
        "#                 tokenizer=tokenizer,\n",
        "#                 data_collator=data_collator,\n",
        "#                 compute_metrics=compute_metrics)"
      ],
      "metadata": {
        "id": "H5iY1J1GNN1e"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer.train()"
      ],
      "metadata": {
        "id": "WsoLUi_-NPck"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer.save_model('t5_gec_model')"
      ],
      "metadata": {
        "id": "qcNFhZ35NRkm"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r 't5_gec_model.zip' 't5_gec_model'"
      ],
      "metadata": {
        "id": "ghqZYFnKRVOh"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mv t5_gec_model.zip /content/drive/MyDrive/c4_200m"
      ],
      "metadata": {
        "id": "hYN-t7nexnHd"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D_Jd7Kg2xpg_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine tuned"
      ],
      "metadata": {
        "id": "CjvtcmefTxUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "own_train_df, own_test_df = train_test_split(clean_test_data, test_size=0.10, shuffle=True)\n",
        "own_train_df.shape, own_test_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnWHlhNbJtP4",
        "outputId": "a1511454-6220-419c-b651-f5ffbbda12fd"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((692, 3), (77, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "own_train_dataset = Dataset.from_pandas(own_train_df)\n",
        "own_test_dataset = Dataset.from_pandas(own_test_df)"
      ],
      "metadata": {
        "id": "gQ01EMUsJxW0"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining training related arguments\n",
        "batch_size = 16\n",
        "args = Seq2SeqTrainingArguments(output_dir=\"./c4_200m/weights\",\n",
        "                        evaluation_strategy=\"steps\",\n",
        "                        per_device_train_batch_size=batch_size,\n",
        "                        per_device_eval_batch_size=batch_size,\n",
        "                        learning_rate=2e-5,\n",
        "                        num_train_epochs=50,\n",
        "                        weight_decay=0.01,\n",
        "                        save_total_limit=2,\n",
        "                        predict_with_generate=True,\n",
        "                        fp16 = True,\n",
        "                        gradient_accumulation_steps = 6,\n",
        "                        eval_steps = 20,\n",
        "                        save_steps = 20,\n",
        "                        load_best_model_at_end=True,\n",
        "                        logging_dir=\"./logs\",\n",
        "                        report_to='wandb')"
      ],
      "metadata": {
        "id": "cKxOx_39L1tu"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining trainer \n",
        "fine_tune_trainer = Seq2SeqTrainer(model=model, \n",
        "                args=args,\n",
        "                train_dataset= GrammarDataset(own_train_dataset, tokenizer),\n",
        "                eval_dataset=GrammarDataset(own_test_dataset, tokenizer),\n",
        "                tokenizer=tokenizer,\n",
        "                data_collator=data_collator,\n",
        "                compute_metrics=compute_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0CJ35i6Kipi",
        "outputId": "67088244-3e44-490c-c8cc-bbd9a43f2e61"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cuda_amp half precision backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t7dGKN9ALjnF",
        "outputId": "9586fdf4-ffda-4115-ba93-81cacd5bbe60"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 692\n",
            "  Num Epochs = 50\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 96\n",
            "  Gradient Accumulation steps = 6\n",
            "  Total optimization steps = 350\n",
            "  Number of trainable parameters = 222903552\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230130_162330-ydkd05m4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/gbc2022/huggingface/runs/ydkd05m4\" target=\"_blank\">virtuous-dumpling-9</a></strong> to <a href=\"https://wandb.ai/gbc2022/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href=\"https://wandb.ai/gbc2022/huggingface\" target=\"_blank\">https://wandb.ai/gbc2022/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href=\"https://wandb.ai/gbc2022/huggingface/runs/ydkd05m4\" target=\"_blank\">https://wandb.ai/gbc2022/huggingface/runs/ydkd05m4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='350' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [350/350 10:37, Epoch 49/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.405216</td>\n",
              "      <td>84.862000</td>\n",
              "      <td>76.296500</td>\n",
              "      <td>83.552500</td>\n",
              "      <td>83.547800</td>\n",
              "      <td>14.805200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.309261</td>\n",
              "      <td>88.181800</td>\n",
              "      <td>80.150800</td>\n",
              "      <td>87.128400</td>\n",
              "      <td>87.131300</td>\n",
              "      <td>14.662300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.269636</td>\n",
              "      <td>91.406700</td>\n",
              "      <td>83.794500</td>\n",
              "      <td>90.716300</td>\n",
              "      <td>90.901000</td>\n",
              "      <td>14.662300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.249970</td>\n",
              "      <td>91.591400</td>\n",
              "      <td>84.435000</td>\n",
              "      <td>91.361900</td>\n",
              "      <td>91.418100</td>\n",
              "      <td>14.753200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.241678</td>\n",
              "      <td>92.134300</td>\n",
              "      <td>85.621300</td>\n",
              "      <td>91.995800</td>\n",
              "      <td>92.015500</td>\n",
              "      <td>14.740300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.237786</td>\n",
              "      <td>92.378000</td>\n",
              "      <td>86.144800</td>\n",
              "      <td>92.272700</td>\n",
              "      <td>92.276800</td>\n",
              "      <td>14.727300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.235123</td>\n",
              "      <td>92.184700</td>\n",
              "      <td>85.811700</td>\n",
              "      <td>92.022900</td>\n",
              "      <td>92.071800</td>\n",
              "      <td>14.727300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.233947</td>\n",
              "      <td>92.209600</td>\n",
              "      <td>85.843000</td>\n",
              "      <td>92.067400</td>\n",
              "      <td>92.102000</td>\n",
              "      <td>14.701300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.232694</td>\n",
              "      <td>92.268900</td>\n",
              "      <td>86.048300</td>\n",
              "      <td>92.111800</td>\n",
              "      <td>92.151100</td>\n",
              "      <td>14.675300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.230588</td>\n",
              "      <td>92.199500</td>\n",
              "      <td>85.823700</td>\n",
              "      <td>92.057900</td>\n",
              "      <td>92.088800</td>\n",
              "      <td>14.701300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.231190</td>\n",
              "      <td>92.199500</td>\n",
              "      <td>85.823700</td>\n",
              "      <td>92.057900</td>\n",
              "      <td>92.088800</td>\n",
              "      <td>14.701300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.230955</td>\n",
              "      <td>92.199500</td>\n",
              "      <td>85.823700</td>\n",
              "      <td>92.057900</td>\n",
              "      <td>92.088800</td>\n",
              "      <td>14.701300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.230044</td>\n",
              "      <td>92.129800</td>\n",
              "      <td>85.638300</td>\n",
              "      <td>92.002400</td>\n",
              "      <td>92.036100</td>\n",
              "      <td>14.714300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.231258</td>\n",
              "      <td>92.004400</td>\n",
              "      <td>85.212900</td>\n",
              "      <td>91.837500</td>\n",
              "      <td>91.907300</td>\n",
              "      <td>14.714300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.231864</td>\n",
              "      <td>91.802900</td>\n",
              "      <td>85.058000</td>\n",
              "      <td>91.675200</td>\n",
              "      <td>91.729300</td>\n",
              "      <td>14.727300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.231847</td>\n",
              "      <td>91.802900</td>\n",
              "      <td>85.058000</td>\n",
              "      <td>91.675200</td>\n",
              "      <td>91.729300</td>\n",
              "      <td>14.727300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.232016</td>\n",
              "      <td>91.802900</td>\n",
              "      <td>85.058000</td>\n",
              "      <td>91.675200</td>\n",
              "      <td>91.729300</td>\n",
              "      <td>14.727300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 77\n",
            "  Batch size = 16\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Saving model checkpoint to ./c4_200m/weights/checkpoint-20\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-20/config.json\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-20/generation_config.json\n",
            "Model weights saved in ./c4_200m/weights/checkpoint-20/pytorch_model.bin\n",
            "tokenizer config file saved in ./c4_200m/weights/checkpoint-20/tokenizer_config.json\n",
            "Special tokens file saved in ./c4_200m/weights/checkpoint-20/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 77\n",
            "  Batch size = 16\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Saving model checkpoint to ./c4_200m/weights/checkpoint-40\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-40/config.json\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-40/generation_config.json\n",
            "Model weights saved in ./c4_200m/weights/checkpoint-40/pytorch_model.bin\n",
            "tokenizer config file saved in ./c4_200m/weights/checkpoint-40/tokenizer_config.json\n",
            "Special tokens file saved in ./c4_200m/weights/checkpoint-40/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 77\n",
            "  Batch size = 16\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Saving model checkpoint to ./c4_200m/weights/checkpoint-60\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-60/config.json\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-60/generation_config.json\n",
            "Model weights saved in ./c4_200m/weights/checkpoint-60/pytorch_model.bin\n",
            "tokenizer config file saved in ./c4_200m/weights/checkpoint-60/tokenizer_config.json\n",
            "Special tokens file saved in ./c4_200m/weights/checkpoint-60/special_tokens_map.json\n",
            "Deleting older checkpoint [c4_200m/weights/checkpoint-20] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 77\n",
            "  Batch size = 16\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Saving model checkpoint to ./c4_200m/weights/checkpoint-80\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-80/config.json\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-80/generation_config.json\n",
            "Model weights saved in ./c4_200m/weights/checkpoint-80/pytorch_model.bin\n",
            "tokenizer config file saved in ./c4_200m/weights/checkpoint-80/tokenizer_config.json\n",
            "Special tokens file saved in ./c4_200m/weights/checkpoint-80/special_tokens_map.json\n",
            "Deleting older checkpoint [c4_200m/weights/checkpoint-40] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 77\n",
            "  Batch size = 16\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Saving model checkpoint to ./c4_200m/weights/checkpoint-100\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-100/config.json\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-100/generation_config.json\n",
            "Model weights saved in ./c4_200m/weights/checkpoint-100/pytorch_model.bin\n",
            "tokenizer config file saved in ./c4_200m/weights/checkpoint-100/tokenizer_config.json\n",
            "Special tokens file saved in ./c4_200m/weights/checkpoint-100/special_tokens_map.json\n",
            "Deleting older checkpoint [c4_200m/weights/checkpoint-60] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 77\n",
            "  Batch size = 16\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Saving model checkpoint to ./c4_200m/weights/checkpoint-120\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-120/config.json\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-120/generation_config.json\n",
            "Model weights saved in ./c4_200m/weights/checkpoint-120/pytorch_model.bin\n",
            "tokenizer config file saved in ./c4_200m/weights/checkpoint-120/tokenizer_config.json\n",
            "Special tokens file saved in ./c4_200m/weights/checkpoint-120/special_tokens_map.json\n",
            "Deleting older checkpoint [c4_200m/weights/checkpoint-80] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 77\n",
            "  Batch size = 16\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Saving model checkpoint to ./c4_200m/weights/checkpoint-140\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-140/config.json\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-140/generation_config.json\n",
            "Model weights saved in ./c4_200m/weights/checkpoint-140/pytorch_model.bin\n",
            "tokenizer config file saved in ./c4_200m/weights/checkpoint-140/tokenizer_config.json\n",
            "Special tokens file saved in ./c4_200m/weights/checkpoint-140/special_tokens_map.json\n",
            "Deleting older checkpoint [c4_200m/weights/checkpoint-100] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 77\n",
            "  Batch size = 16\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Saving model checkpoint to ./c4_200m/weights/checkpoint-160\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-160/config.json\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-160/generation_config.json\n",
            "Model weights saved in ./c4_200m/weights/checkpoint-160/pytorch_model.bin\n",
            "tokenizer config file saved in ./c4_200m/weights/checkpoint-160/tokenizer_config.json\n",
            "Special tokens file saved in ./c4_200m/weights/checkpoint-160/special_tokens_map.json\n",
            "Deleting older checkpoint [c4_200m/weights/checkpoint-120] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 77\n",
            "  Batch size = 16\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Saving model checkpoint to ./c4_200m/weights/checkpoint-180\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-180/config.json\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-180/generation_config.json\n",
            "Model weights saved in ./c4_200m/weights/checkpoint-180/pytorch_model.bin\n",
            "tokenizer config file saved in ./c4_200m/weights/checkpoint-180/tokenizer_config.json\n",
            "Special tokens file saved in ./c4_200m/weights/checkpoint-180/special_tokens_map.json\n",
            "Deleting older checkpoint [c4_200m/weights/checkpoint-140] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 77\n",
            "  Batch size = 16\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Saving model checkpoint to ./c4_200m/weights/checkpoint-200\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-200/config.json\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-200/generation_config.json\n",
            "Model weights saved in ./c4_200m/weights/checkpoint-200/pytorch_model.bin\n",
            "tokenizer config file saved in ./c4_200m/weights/checkpoint-200/tokenizer_config.json\n",
            "Special tokens file saved in ./c4_200m/weights/checkpoint-200/special_tokens_map.json\n",
            "Deleting older checkpoint [c4_200m/weights/checkpoint-160] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 77\n",
            "  Batch size = 16\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Saving model checkpoint to ./c4_200m/weights/checkpoint-220\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-220/config.json\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-220/generation_config.json\n",
            "Model weights saved in ./c4_200m/weights/checkpoint-220/pytorch_model.bin\n",
            "tokenizer config file saved in ./c4_200m/weights/checkpoint-220/tokenizer_config.json\n",
            "Special tokens file saved in ./c4_200m/weights/checkpoint-220/special_tokens_map.json\n",
            "Deleting older checkpoint [c4_200m/weights/checkpoint-180] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 77\n",
            "  Batch size = 16\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Saving model checkpoint to ./c4_200m/weights/checkpoint-240\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-240/config.json\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-240/generation_config.json\n",
            "Model weights saved in ./c4_200m/weights/checkpoint-240/pytorch_model.bin\n",
            "tokenizer config file saved in ./c4_200m/weights/checkpoint-240/tokenizer_config.json\n",
            "Special tokens file saved in ./c4_200m/weights/checkpoint-240/special_tokens_map.json\n",
            "Deleting older checkpoint [c4_200m/weights/checkpoint-220] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 77\n",
            "  Batch size = 16\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Saving model checkpoint to ./c4_200m/weights/checkpoint-260\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-260/config.json\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-260/generation_config.json\n",
            "Model weights saved in ./c4_200m/weights/checkpoint-260/pytorch_model.bin\n",
            "tokenizer config file saved in ./c4_200m/weights/checkpoint-260/tokenizer_config.json\n",
            "Special tokens file saved in ./c4_200m/weights/checkpoint-260/special_tokens_map.json\n",
            "Deleting older checkpoint [c4_200m/weights/checkpoint-200] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 77\n",
            "  Batch size = 16\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Saving model checkpoint to ./c4_200m/weights/checkpoint-280\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-280/config.json\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-280/generation_config.json\n",
            "Model weights saved in ./c4_200m/weights/checkpoint-280/pytorch_model.bin\n",
            "tokenizer config file saved in ./c4_200m/weights/checkpoint-280/tokenizer_config.json\n",
            "Special tokens file saved in ./c4_200m/weights/checkpoint-280/special_tokens_map.json\n",
            "Deleting older checkpoint [c4_200m/weights/checkpoint-240] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 77\n",
            "  Batch size = 16\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Saving model checkpoint to ./c4_200m/weights/checkpoint-300\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-300/config.json\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-300/generation_config.json\n",
            "Model weights saved in ./c4_200m/weights/checkpoint-300/pytorch_model.bin\n",
            "tokenizer config file saved in ./c4_200m/weights/checkpoint-300/tokenizer_config.json\n",
            "Special tokens file saved in ./c4_200m/weights/checkpoint-300/special_tokens_map.json\n",
            "Deleting older checkpoint [c4_200m/weights/checkpoint-280] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 77\n",
            "  Batch size = 16\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Saving model checkpoint to ./c4_200m/weights/checkpoint-320\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-320/config.json\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-320/generation_config.json\n",
            "Model weights saved in ./c4_200m/weights/checkpoint-320/pytorch_model.bin\n",
            "tokenizer config file saved in ./c4_200m/weights/checkpoint-320/tokenizer_config.json\n",
            "Special tokens file saved in ./c4_200m/weights/checkpoint-320/special_tokens_map.json\n",
            "Deleting older checkpoint [c4_200m/weights/checkpoint-300] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 77\n",
            "  Batch size = 16\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Saving model checkpoint to ./c4_200m/weights/checkpoint-340\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-340/config.json\n",
            "Configuration saved in ./c4_200m/weights/checkpoint-340/generation_config.json\n",
            "Model weights saved in ./c4_200m/weights/checkpoint-340/pytorch_model.bin\n",
            "tokenizer config file saved in ./c4_200m/weights/checkpoint-340/tokenizer_config.json\n",
            "Special tokens file saved in ./c4_200m/weights/checkpoint-340/special_tokens_map.json\n",
            "Deleting older checkpoint [c4_200m/weights/checkpoint-320] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./c4_200m/weights/checkpoint-260 (score: 0.23004449903964996).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=350, training_loss=0.2059092276436942, metrics={'train_runtime': 654.1586, 'train_samples_per_second': 52.892, 'train_steps_per_second': 0.535, 'total_flos': 1659186650050560.0, 'train_loss': 0.2059092276436942, 'epoch': 49.95})"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_trainer.save_model(\"fine_tuned_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52zqXTiqTIE6",
        "outputId": "eb14a991-6989-46c2-d201-a3c5d19eaec2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to fine_tuned_model\n",
            "Configuration saved in fine_tuned_model/config.json\n",
            "Configuration saved in fine_tuned_model/generation_config.json\n",
            "Model weights saved in fine_tuned_model/pytorch_model.bin\n",
            "tokenizer config file saved in fine_tuned_model/tokenizer_config.json\n",
            "Special tokens file saved in fine_tuned_model/special_tokens_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r 'fine_tuned_model.zip' 'fine_tuned_model'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yk4TXtAkWhRO",
        "outputId": "2c98393b-1aa9-4093-a133-96eedd87d617"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: fine_tuned_model/ (stored 0%)\n",
            "  adding: fine_tuned_model/spiece.model (deflated 48%)\n",
            "  adding: fine_tuned_model/generation_config.json (deflated 29%)\n",
            "  adding: fine_tuned_model/special_tokens_map.json (deflated 86%)\n",
            "  adding: fine_tuned_model/training_args.bin (deflated 49%)\n",
            "  adding: fine_tuned_model/tokenizer_config.json (deflated 82%)\n",
            "  adding: fine_tuned_model/pytorch_model.bin (deflated 11%)\n",
            "  adding: fine_tuned_model/config.json (deflated 62%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQzJE6ybKPaR"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d2c7820-0951-470c-e4ef-bf2f74d8e097",
        "id": "05rKa7c5Vny0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file spiece.model\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading configuration file fine_tuned_model/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"t5-base\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 3072,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file fine_tuned_model/pytorch_model.bin\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at fine_tuned_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "loading configuration file fine_tuned_model/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"_from_model_config\": true,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "#model_name = 't5_gec_model'\n",
        "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "#tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "#model = T5ForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
        "\n",
        "fine_tune_model_name = \"fine_tuned_model\"\n",
        "fine_tuned_tokenizer = T5Tokenizer.from_pretrained(fine_tune_model_name)\n",
        "fine_tuned_model = T5ForConditionalGeneration.from_pretrained(fine_tune_model_name).to(torch_device)\n",
        "\n",
        "\n",
        "def correct_grammar(input_text,num_return_sequences, model=model):\n",
        "  batch = tokenizer([input_text],truncation=True,padding='max_length',max_length=64, return_tensors=\"pt\").to(torch_device)\n",
        "  translated = model.generate(**batch,max_length=64,num_beams=4, num_return_sequences=num_return_sequences, temperature=1.5)\n",
        "  tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
        "  return tgt_text\n",
        "\n",
        "def fine_tuned_correct_grammar(input_text,num_return_sequences):\n",
        "  batch = fine_tuned_tokenizer([input_text],truncation=True,padding='max_length',max_length=64, return_tensors=\"pt\").to(torch_device)\n",
        "  translated = fine_tuned_model.generate(**batch,max_length=64,num_beams=4, num_return_sequences=num_return_sequences, temperature=1.5)\n",
        "  tgt_text = fine_tuned_tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
        "  return tgt_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fd6b8c5-b353-48f3-9a1b-0b19ca000bd0",
        "id": "RYavgzxzVny1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['He are moving here.', \"He's moving here.\", 'He is moving here.']\n",
            "['He are moving here.', 'He is moving here.', \"He're moving here.\"]\n"
          ]
        }
      ],
      "source": [
        "text = 'He are moving here.'\n",
        "print(correct_grammar(text, num_return_sequences=3))\n",
        "print(fine_tuned_correct_grammar(text, num_return_sequences=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c73b1a2-b144-461d-a543-5c14389f046a",
        "id": "4soV4aZYVny2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"I think it's a good thing.\", \"I think it's a good thing, I think it's a good thing.\", \"I think it's a good thing, but I think it's a good thing.\"]\n",
            "['I think it is.', \"I think it's a good thing.\", \"I think it's a good one.\"]\n"
          ]
        }
      ],
      "source": [
        "text = 'I think it'\n",
        "print(correct_grammar(text, num_return_sequences=3))\n",
        "print(fine_tuned_correct_grammar(text, num_return_sequences=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90a521f1-3c06-4d1e-dcf8-d81b3a155821",
        "id": "75-ac04TVny2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['What are insulin pump not available in dogs and cats?', 'What are insulin pumps not available in dogs and cats?', 'What is the insulin pump not available in dogs and cats?']\n",
            "['What are insulin pump not available in dogs and cats?', 'What is the insulin pump not available in dogs and cats?', 'What are insulin pumps not available in dogs and cats?']\n"
          ]
        }
      ],
      "source": [
        "text = \"What are insulin pump not available in dogs and cats?\"\n",
        "print(correct_grammar(text, num_return_sequences=3))\n",
        "print(fine_tuned_correct_grammar(text, num_return_sequences=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "AX_peD3xh-fH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cef6516b-b7cf-47c4-a01d-311e3221d6e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['You can look at trying to reintroduce brushing by using a soft bristled kids toothbrush and letting them just start by licking the toothpaste.', 'You can look at trying to reintroduce brushing by using soft bristled kids toothbrush and letting them just start by licking the toothpaste.', \"You can look at trying to reintroduce brushing by using soft bristled kids' toothbrush and letting them just start by licking the toothpaste.\"]\n",
            "['You can look at trying to reintroduce brushing by using a soft bristled kids toothbrush and letting them just start by licking the toothpaste.', \"You can look at trying to reintroduce brushing by using a soft bristled kid's toothbrush and letting them just start by licking the toothpaste.\", 'You can look at trying to reintroduce brushing by using a soft bristled kids toothbrush and letting them just start by licking toothpaste.']\n"
          ]
        }
      ],
      "source": [
        "text = \"You can look at trying to reintroduce brushing by using a soft bristled kids toothbrush and letting them just start by licking the toothpaste.\"\n",
        "print(correct_grammar(text, num_return_sequences=3))\n",
        "print(fine_tuned_correct_grammar(text, num_return_sequences=3))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pCmL8EQgsl_9"
      },
      "execution_count": 48,
      "outputs": []
    }
  ]
}